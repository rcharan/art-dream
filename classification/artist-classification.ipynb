{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities import Timer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, InputLayer, Dropout, Dense\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data as a TensorFlow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largely based on the TensorFlow [tutorial](https://www.tensorflow.org/tutorials/load_data/images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = height = 224\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classnames\n",
    "\n",
    "df = pd.read_excel('../dataset/artist-breakdown-annotated.xlsx')\n",
    "df = df[df.fillna(0).keep.astype(bool)]\n",
    "class_names = df.artist.unique()\n",
    "class_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_subdir, \n",
    "                 shuffle = True, shuffle_buffer_size=1000,\n",
    "                 batch_size = batch_size,\n",
    "                 width      = width,\n",
    "                 height     = height\n",
    "                ):\n",
    "    # Load the list of file names in the form of data_dir/class_name/file_name.jpg\n",
    "    data_dir = pathlib.Path('../dataset/images/') / pathlib.Path(data_subdir)\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "\n",
    "    dataset_size = len(list(list_ds))\n",
    "    \n",
    "    # Function to get the label\n",
    "    def get_label(file_path):\n",
    "        parts = tf.strings.split(file_path, os.path.sep)\n",
    "        return parts[-2] == class_names\n",
    "    \n",
    "    # Function to get the image\n",
    "    def decode_img(file_path):\n",
    "        # Load the image\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        \n",
    "        # Scale image pixels to 0/1\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        # Resize\n",
    "        return tf.image.resize(img, [width, height])\n",
    "    \n",
    "    # Combine both processes\n",
    "    def process_path(file_path):\n",
    "        return decode_img(file_path), get_label(file_path)\n",
    "    \n",
    "    # Create the dataset\n",
    "    ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if shuffle:\n",
    "        if shuffle_buffer_size is not None:\n",
    "            ds = ds.shuffle(buffer_size = shuffle_buffer_size)\n",
    "        else:\n",
    "            ds = ds.shuffle(buffer_size = dataset_size)\n",
    "    \n",
    "    ds = ds.repeat().batch(batch_size).prefetch(buffer_size = AUTOTUNE)    \n",
    "    return ds, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a batch\n",
    "peek, peek_size = load_dataset('train', shuffle_buffer_size=32)\n",
    "image_batch, label_batch = next(iter(peek))\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(class_names[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')\n",
    "\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier\n",
    "\n",
    "The original DeepDream was built using [GoogLeNet](https://arxiv.org/abs/1409.4842) which won the ILSVRC (ImageNet Large Scale Visual Recognition Competition) in [2014](http://image-net.org/challenges/LSVRC/2014/).\n",
    "\n",
    "In the spirit of keeping things simple, a first attempt will be made using a VGGNet (from the [Visual Geometry Group at Oxford](https://www.robots.ox.ac.uk/~vgg/)). This placed 2nd in ILSVRC 2014 but is substantially simpler in architecture, being essentially a vanilla convolutional net.\n",
    "\n",
    "We don't want to use the pre-existing weights, so we will attempt to train from scratch. You can see the model on the tensorflow [github](https://github.com/tensorflow/tensorflow/blob/23c3bdaacdc27bb82dfd1772efefad687508923a/tensorflow/python/keras/applications/vgg19.py). Note that it is not precisely the same as described in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(include_top = True, weights = None, input_shape = (width, height, 3), classes = len(class_names))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "metrics   = [\n",
    "    CategoricalAccuracy(name = 'accuracy'),\n",
    "    TopKCategoricalAccuracy(3, name = 'top-3-accuracy'),\n",
    "    TopKCategoricalAccuracy(5, name = 'top-5-accuracy'),\n",
    "]\n",
    "\n",
    "model.compile(optimizer, \n",
    "              loss = CategoricalCrossentropy(),\n",
    "              metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_size       = load_dataset('train')\n",
    "validate, validate_size = load_dataset('validate', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    CSVLogger('./logs/training-log.csv', append = True),\n",
    "    EarlyStopping(patience = 5, restore_best_weights = True),\n",
    "    ModelCheckpoint(filepath='vgg19-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "    TerminateOnNaN()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data  = validate,\n",
    "    epochs           = 1,\n",
    "    verbose          = 1,\n",
    "    callbacks        = callbacks,\n",
    "    validation_steps = validate_size // batch_size + 1,\n",
    "    steps_per_epoch  = train_size    // batch_size + 1,\n",
    "    initial_epoch    = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
