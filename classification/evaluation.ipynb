{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.applications     as     applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utilities/')\n",
    "from utilities import Timer, show_image, DreamImage, DeepDream, class_names, ProgressBar, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "width = height = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19-INet-down2-b'\n",
    "base_model = load_model(f'../classification/logs/models/{model_name}.hdf5')\n",
    "\n",
    "# Remove dropout\n",
    "model = Sequential()\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, Dropout):\n",
    "        pass\n",
    "    else:\n",
    "        model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data in Special Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of file names in the form of data_dir/class_name/file_name.jpg\n",
    "data_subdir = 'test'\n",
    "data_dir = pathlib.Path('../dataset/images/') / pathlib.Path(data_subdir)\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "\n",
    "dataset_size = len(list(list_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the label\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == class_names\n",
    "\n",
    "# Function to get the image\n",
    "def decode_img(file_path):\n",
    "    # Load the image\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "    # Resize\n",
    "    return tf.image.resize(img, [width, height])\n",
    "\n",
    "def preprocess_img(img, label, file_path):\n",
    "    return applications.vgg19.preprocess_input(img), label, tf.convert_to_tensor(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both processes\n",
    "def process_path(file_path):\n",
    "    return decode_img(file_path), get_label(file_path), file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img_batch, label_batch, file_path_batch):\n",
    "    return model(img_batch), label_batch, file_path_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "ds = ds.map(preprocess_img)\n",
    "ds = ds.batch(batch_size).prefetch(buffer_size = AUTOTUNE)\n",
    "ds = ds.map(classify_image)\n",
    "ds = ds.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Predictions on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = ProgressBar(dataset_size // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 92/92 7.0s per loop          \n"
     ]
    }
   ],
   "source": [
    "class_batches = []\n",
    "label_batches = []\n",
    "file_batches  = []\n",
    "bar.start()\n",
    "iterations = 0\n",
    "for class_batch, label_batch, file_batch in ds:\n",
    "    class_batches.append(class_batch)\n",
    "    label_batches.append(label_batch)\n",
    "    file_batches.append(file_batch)\n",
    "    iterations+=1\n",
    "    bar.update(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Predictions into a Convenient Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a single array\n",
    "def concat_batches(batch_list):\n",
    "    batch_list = [tensor.numpy() for tensor in batch_list]\n",
    "    return np.concatenate(batch_list)\n",
    "\n",
    "y_predict_proba = concat_batches(class_batches)\n",
    "y_true          = concat_batches(label_batches)\n",
    "file_paths      = concat_batches(file_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hard Predictions\n",
    "y_pred = []\n",
    "for a in y_predict_proba:\n",
    "    out = np.zeros(len(a))\n",
    "    out[a.argmax()] = 1\n",
    "    out = np.expand_dims(out, 0)\n",
    "    y_pred.append(out)\n",
    "y_pred = np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions and True Values as Labels\n",
    "y_pred_label = []\n",
    "for a in y_predict_proba:\n",
    "    out = class_names[a.argmax()]\n",
    "    y_pred_label.append(out)\n",
    "\n",
    "y_true_label = []\n",
    "for a in y_true:\n",
    "    out = class_names[a.argmax()]\n",
    "    y_true_label.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df            = pd.Series(file_paths  , name = 'file')\n",
    "y_pred_label       = pd.Series(y_pred_label, name = 'pred_label')\n",
    "y_true_label       = pd.Series(y_true_label, name = 'true_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.concat([file_df, y_pred_label, y_true_label], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba_df = pd.DataFrame(y_predict_proba, index = predict_df.index)\n",
    "y_true_df          = pd.DataFrame(y_true         , index = predict_df.index)\n",
    "y_pred_df          = pd.DataFrame(y_pred         , index = predict_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = [(y_predict_proba_df, 'predict_proba'),\n",
    "              (y_true_df         , 'y_true')       ,\n",
    "              (y_pred_df         , 'y_pred')\n",
    "             ]\n",
    "\n",
    "one_hot_df = [df.rename(lambda col : f'{name}_{col}', axis = 'columns') for df, name in one_hot_df]\n",
    "one_hot_df = pd.concat(one_hot_df, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.to_csv('predictions.csv')\n",
    "one_hot_df.to_csv('one_hot_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_csv('predictions.csv')\n",
    "one_hot_df = pd.read_csv('one_hot_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "cm = confusion_matrix(y_true_label, y_pred_label)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 20))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=class_names)\n",
    "disp.plot(include_values=True,\n",
    "                 cmap=sns.cubehelix_palette(light=1, as_cmap=True), ax=ax, xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
