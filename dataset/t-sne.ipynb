{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.applications     as     applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utilities/')\n",
    "from utilities import Timer, show_image, DreamImage, DeepDream, class_names, ProgressBar, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "width = height = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19-INet-down2-b'\n",
    "base_model = load_model(f'../classification/logs/models/{model_name}.hdf5')\n",
    "\n",
    "# Remove dropout\n",
    "model = Sequential()\n",
    "for layer in base_model.layers[:-1]:\n",
    "    if isinstance(layer, Dropout):\n",
    "        pass\n",
    "    else:\n",
    "        model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data in Special Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of file names in the form of data_dir/class_name/file_name.jpg\n",
    "data_subdir = 'test'\n",
    "data_dir = pathlib.Path('../dataset/images/') / pathlib.Path(data_subdir)\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "\n",
    "dataset_size = len(list(list_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the label\n",
    "#  Modification: get just the class name, not the vector\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "# Function to get the image\n",
    "def decode_img(file_path):\n",
    "    # Load the image\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "    # Resize\n",
    "    return tf.image.resize(img, [width, height])\n",
    "\n",
    "# Preprocess\n",
    "def preprocess_img(img, label, file_path):\n",
    "    return applications.vgg19.preprocess_input(img), label, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both processes\n",
    "def process_path(file_path):\n",
    "    return decode_img(file_path), get_label(file_path), file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_image(img_batch, label_batch, file_path_batch):\n",
    "    return model(img_batch), label_batch, file_path_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "ds = ds.map(preprocess_img)\n",
    "ds = ds.batch(batch_size).prefetch(buffer_size = AUTOTUNE)\n",
    "ds = ds.map(embed_image)\n",
    "ds = ds.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Embedding on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = ProgressBar(dataset_size // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================>] 92/92 7.0s per loop          \n"
     ]
    }
   ],
   "source": [
    "class_batches     = []\n",
    "label_batches     = []\n",
    "file_path_batches = []\n",
    "bar.start()\n",
    "iterations = 0\n",
    "for class_batch, label_batch, file_path_batch in ds:\n",
    "    class_batches.append(class_batch)\n",
    "    label_batches.append(label_batch)\n",
    "    file_path_batches.append(file_path_batch)\n",
    "    iterations+=1\n",
    "    bar.update(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Embeddings into a Convenient Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a single array\n",
    "def concat_batches(batch_list):\n",
    "    batch_list = [tensor.numpy() for tensor in batch_list]\n",
    "    return np.concatenate(batch_list)\n",
    "\n",
    "embedding  = concat_batches(class_batches)\n",
    "labels     = concat_batches(label_batches)\n",
    "file_paths = concat_batches(file_path_batches)\n",
    "\n",
    "df = pd.concat([pd.Series(labels, name = 'artist'), pd.Series(file_paths, name = 'file_path'), pd.DataFrame(embedding)], axis = 'columns')\n",
    "df.to_csv(f'{model_name}-embedding.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
