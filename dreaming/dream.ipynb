{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, AvgPool2D, InputLayer, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utilities import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image display utility\n",
    "def show_image(image):\n",
    "    figsize = image.shape.as_list()[:-1]\n",
    "    figsize = tuple(size / 72 for size in figsize)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../dream-base-images/marco3.png'\n",
    "\n",
    "width = height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classnames\n",
    "df = pd.read_excel('../dataset/artist-breakdown-annotated.xlsx')\n",
    "df = df[df.fillna(0).keep.astype(bool)]\n",
    "class_names = df.artist.unique()\n",
    "class_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19-INet-down3'\n",
    "base_model = load_model(f'../classification/logs/models/{model_name}.hdf5')\n",
    "\n",
    "# Replace max pooling with avg pooling to promote gradient flow\n",
    "model = Sequential([InputLayer(input_shape = (width, height, 3))])\n",
    "\n",
    "for layer in base_model.layers[:-1]:\n",
    "    if isinstance(layer, MaxPooling2D):\n",
    "        pool = AvgPool2D().from_config(layer.get_config())\n",
    "        model.add(pool)\n",
    "    elif isinstance(layer, Dropout):\n",
    "        pass\n",
    "    else:\n",
    "        model.add(layer)\n",
    "        \n",
    "    if layer.name == 'block5_conv2':\n",
    "        break\n",
    "\n",
    "\n",
    "# # Add the top layer without softmax\n",
    "# top_config = base_model.layers[-1].get_config()\n",
    "# top_config['activation'] = 'linear'\n",
    "# top_layer = base_model.layers[-1].from_config(top_config)\n",
    "# model.add(top_layer)\n",
    "\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to manage the image processing pre- and post-dream.\n",
    "# Terminology\n",
    "#  - The base image is what is dreamt upon by the dreamer.\n",
    "#     The base image itself can be an earlier dream\n",
    "#  - After dreaming, a dream should be registered with the DreamImage instance\n",
    "#  - Then it can be decoded using a normalization scheme and optional resizing\n",
    "\n",
    "# Scalers\n",
    "def min_max_scale(tensor):\n",
    "    min_ = tf.reduce_min(tensor)\n",
    "    max_ = tf.reduce_max(tensor)\n",
    "    return (tensor - min_) / (max_ - min_)\n",
    "def clip_scaler(tensor):\n",
    "    return (1/2) * (1 + tf.clip_by_value(tensor, -1, 1))\n",
    "\n",
    "\n",
    "class DreamImage:\n",
    "    def __init__(self, image_path, width, height, normalizer = 'min-max'):\n",
    "        # Load the image from disk\n",
    "        self.img = tf.io.read_file(image_path)\n",
    "        if image_path.endswith('.png'):\n",
    "            self.img = tf.image.decode_png(self.img, channels = 3)\n",
    "        elif image_path.endswith('.jpg'):\n",
    "            self.img = tf.image.decode_jpg(self.img, channels = 3)\n",
    "        else:\n",
    "            raise TypeError(f'File format for {path} not supported or detected')\n",
    "        self.img = tf.image.convert_image_dtype(self.img, tf.float32)\n",
    "        \n",
    "        # Set the target width and height\n",
    "        self.width  = width\n",
    "        self.height = height\n",
    "        \n",
    "        # Set the normalizer\n",
    "        normalizers = {\n",
    "            'sigmoid' : tf.sigmoid,\n",
    "            'min-max' : min_max_scale,\n",
    "            'clip'    : clip_scaler\n",
    "        }\n",
    "        self.normalizer = normalizers[normalizer]\n",
    "        \n",
    "    def show_base(self):\n",
    "        show_image(self.img)\n",
    "        \n",
    "    def prepare_base(self):\n",
    "        # Resize\n",
    "        self.resized_base = tf.image.resize(self.img, [self.width, self.height])\n",
    "        \n",
    "        # Center the image\n",
    "        # self.mean_correction = tf.reduce_mean(self.resized_base)\n",
    "        self.mean_correction = 0\n",
    "        \n",
    "        # img = self.resized_base - self.mean_correction\n",
    "        img = self.resized_base\n",
    "        \n",
    "        # Add noise\n",
    "        img = img + tf.random.normal(img.shape, stddev = .05)\n",
    "        \n",
    "        img = tf.expand_dims(img, axis = 0)\n",
    "        return img\n",
    "        \n",
    "    def decode_dream(self, dream, full_size = False):\n",
    "        # Prepare the dream\n",
    "        dream    = tf.squeeze(dream)\n",
    "        dream    = self.normalizer(dream)\n",
    "        \n",
    "        if full_size:\n",
    "            dream_delta = dream - self.resized_base\n",
    "            dream_delta = tf.image.resize(dream_delta, self.img.shape.as_list()[:-1])\n",
    "            img         = dream_delta + self.img\n",
    "        else:\n",
    "            img         = dream\n",
    "        img         = img - tf.reduce_min(img)\n",
    "        img         = img / tf.reduce_max(img)\n",
    "        return img\n",
    "\n",
    "    def show_dream(self, dream, full_size = False):\n",
    "        dream = self.decode_dream(dream, full_size = full_size)\n",
    "        show_image(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model, steps, learning_rate, artist_vect):\n",
    "        self.model         = model\n",
    "        self.steps         = tf.convert_to_tensor(steps, dtype = tf.int32)\n",
    "        self.learning_rate = tf.convert_to_tensor(learning_rate, dtype = tf.float32)\n",
    "        self.artist_vect   = tf.convert_to_tensor(artist_vect, dtype = tf.float32)\n",
    "        \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[1,None,None,3], dtype=tf.float32),))\n",
    "    def __call__(self, img):\n",
    "        for n in tf.range(self.steps):\n",
    "            # Compute the loss so that the gradient may be computed\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(img)\n",
    "                activations = self.model(img)\n",
    "                loss = tf.reduce_sum(tf.math.square(activations))\n",
    "                # loss        = tf.tensordot(self.artist_vect, activations, [0,1])\n",
    "                # loss        = tf.squeeze(loss)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            # gradients -= tf.math.reduce_mean(gradients)\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*self.learning_rate\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamer = DeepDream(model, 100, 0.01, class_names == 'Pablo Picasso')\n",
    "marco   = DreamImage(image_path, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timer.start()\n",
    "dream = dreamer(marco.prepare_base())\n",
    "Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marco.show_dream(dream, full_size = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a layer of just weights\n",
    "x = keras.layers.Dense(224*224, input_shape = (0, 0), use_bias = True)\n",
    "y = keras.models.Sequential(x)\n",
    "y.build()\n",
    "x.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(min_max_scale(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Deep Dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "\n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "  name = url.split('/')[-1]\n",
    "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "  img = PIL.Image.open(image_path)\n",
    "  if max_dim:\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "  return np.array(img)\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "  img = 255*(img + 1.0)/2.0\n",
    "  return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "  display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "\n",
    "# Downsizing the image makes it easier to work with.\n",
    "original_img = download(url, max_dim=500)\n",
    "show(original_img)\n",
    "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))\n",
    "\n",
    "original_img.shape\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "# Maximize the activations of these layers\n",
    "names = ['mixed3', 'mixed5']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "def calc_loss(img, model):\n",
    "  # Pass forward the image through the model to retrieve the activations.\n",
    "  # Converts the image into a batch of size 1.\n",
    "  img_batch = tf.expand_dims(img, axis=0)\n",
    "  layer_activations = model(img_batch)\n",
    "\n",
    "  losses = []\n",
    "  for act in layer_activations:\n",
    "    loss = tf.math.reduce_mean(act)\n",
    "    losses.append(loss)\n",
    "\n",
    "  return  tf.reduce_sum(losses)\n",
    "\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "  )\n",
    "  def __call__(self, img, steps, step_size):\n",
    "      loss = tf.constant(0.0)\n",
    "      for n in tf.range(steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "          # This needs gradients relative to `img`\n",
    "          # `GradientTape` only watches `tf.Variable`s by default\n",
    "          tape.watch(img)\n",
    "          loss = calc_loss(img, self.model)\n",
    "\n",
    "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "        gradients = tape.gradient(loss, img)\n",
    "\n",
    "        # Normalize the gradients.\n",
    "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "        \n",
    "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "        img = img + gradients*step_size\n",
    "        img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      return loss, img\n",
    "\n",
    "deepdream = DeepDream(dream_model)\n",
    "\n",
    "\n",
    "def run_deep_dream_simple(img, steps=10, step_size=0.01):\n",
    "  # Convert from uint8 to the range expected by the model.\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "  img = tf.convert_to_tensor(img)\n",
    "  step_size = tf.convert_to_tensor(step_size)\n",
    "  steps_remaining = steps\n",
    "  step = 0\n",
    "  while steps_remaining:\n",
    "    if steps_remaining>5:\n",
    "      run_steps = tf.constant(5)\n",
    "    else:\n",
    "      run_steps = tf.constant(steps_remaining)\n",
    "    steps_remaining -= run_steps\n",
    "    step += run_steps\n",
    "\n",
    "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    show(deprocess(img))\n",
    "    print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "\n",
    "  result = deprocess(img)\n",
    "  display.clear_output(wait=True)\n",
    "  show(result)\n",
    "\n",
    "  return result\n",
    "\n",
    "dream_img = run_deep_dream_simple(img=original_img, \n",
    "                                  steps=100, step_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.applications.inception_v3.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timer.start()\n",
    "dream_img = run_deep_dream_simple(img=original_img, \n",
    "                                  steps=100, step_size=0.01)\n",
    "Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timer.start()\n",
    "\n",
    "OCTAVE_SCALE = 1.30\n",
    "\n",
    "img = tf.constant(np.array(original_img))\n",
    "base_shape = tf.shape(img)[:-1]\n",
    "float_base_shape = tf.cast(base_shape, tf.float32)\n",
    "\n",
    "for n in range(-2, 3):\n",
    "  new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape).numpy()\n",
    "\n",
    "  img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "img = tf.image.resize(img, base_shape)\n",
    "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "show(img)\n",
    "\n",
    "Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_roll(img, maxroll):\n",
    "  # Randomly shift the image to avoid tiled boundaries.\n",
    "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
    "  shift_down, shift_right = shift[0],shift[1] \n",
    "  img_rolled = tf.roll(tf.roll(img, shift_right, axis=1), shift_down, axis=0)\n",
    "  return shift_down, shift_right, img_rolled\n",
    "\n",
    "shift_down, shift_right, img_rolled = random_roll(np.array(original_img), 512)\n",
    "show(img_rolled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiledGradients(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
    "  )\n",
    "  def __call__(self, img, tile_size=512):\n",
    "    shift_down, shift_right, img_rolled = random_roll(img, tile_size)\n",
    "\n",
    "    # Initialize the image gradients to zero.\n",
    "    gradients = tf.zeros_like(img_rolled)\n",
    "    \n",
    "    # Skip the last tile, unless there's only one tile.\n",
    "    xs = tf.range(0, img_rolled.shape[0], tile_size)[:-1]\n",
    "    if not tf.cast(len(xs), bool):\n",
    "      xs = tf.constant([0])\n",
    "    ys = tf.range(0, img_rolled.shape[1], tile_size)[:-1]\n",
    "    if not tf.cast(len(ys), bool):\n",
    "      ys = tf.constant([0])\n",
    "\n",
    "    for x in xs:\n",
    "      for y in ys:\n",
    "        # Calculate the gradients for this tile.\n",
    "        with tf.GradientTape() as tape:\n",
    "          # This needs gradients relative to `img_rolled`.\n",
    "          # `GradientTape` only watches `tf.Variable`s by default.\n",
    "          tape.watch(img_rolled)\n",
    "\n",
    "          # Extract a tile out of the image.\n",
    "          img_tile = img_rolled[x:x+tile_size, y:y+tile_size]\n",
    "          loss = calc_loss(img_tile, self.model)\n",
    "\n",
    "        # Update the image gradients for this tile.\n",
    "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
    "\n",
    "    # Undo the random shift applied to the image and its gradients.\n",
    "    gradients = tf.roll(tf.roll(gradients, -shift_right, axis=1), -shift_down, axis=0)\n",
    "\n",
    "    # Normalize the gradients.\n",
    "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "    return gradients \n",
    "\n",
    "get_tiled_gradients = TiledGradients(dream_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
    "                                octaves=range(-2,3), octave_scale=1.3):\n",
    "  base_shape = tf.shape(img)\n",
    "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "  initial_shape = img.shape[:-1]\n",
    "  img = tf.image.resize(img, initial_shape)\n",
    "  for octave in octaves:\n",
    "    # Scale the image based on the octave\n",
    "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "    img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
    "\n",
    "    for step in range(steps_per_octave):\n",
    "      gradients = get_tiled_gradients(img)\n",
    "      img = img + gradients*step_size\n",
    "      img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      if step % 10 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        show(deprocess(img))\n",
    "        print (\"Octave {}, Step {}\".format(octave, step))\n",
    "    \n",
    "  result = deprocess(img)\n",
    "  return result\n",
    "\n",
    "Timer.start()\n",
    "img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "img = tf.image.resize(img, base_shape)\n",
    "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "show(img)\n",
    "Timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test re-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Downsample/upsample is trick\n",
    "img = tf.io.read_file(image_path)\n",
    "img = tf.image.decode_png(img, channels = 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 20))\n",
    "ax.imshow(img)\n",
    "plt.axis('off')\n",
    "print(img.shape)\n",
    "plt.show()\n",
    "\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = tf.image.resize(img, [width, height])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = tf.image.resize(img, [4032, 3024])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 20))\n",
    "ax.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dream Modification 1\n",
    "Run on a VGG19 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    out = tf.keras.applications.vgg19.preprocess_input(image)\n",
    "    out = tf.convert_to_tensor(out)\n",
    "    return out\n",
    "\n",
    "def postprocess_image(image):\n",
    "    image = image.numpy()\n",
    "    image[:, :, 0] += 103.939\n",
    "    image[:, :, 1] += 116.779\n",
    "    image[:, :, 2] += 123.68\n",
    "    out = np.clip(image[:, :, ::-1], 0, 255).astype('uint8')\n",
    "    return tf.convert_to_tensor(out)\n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "\n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "    name = url.split('/')[-1]\n",
    "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "    img = PIL.Image.open(image_path)\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return  tf.reduce_sum(losses)\n",
    "\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # This needs gradients relative to `img`\n",
    "                # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            # img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img\n",
    "\n",
    "    def run_deep_dream_simple(self, img, steps=10, step_size=0.01):\n",
    "        # Convert from uint8 to the range expected by the model.\n",
    "        img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "        img = tf.convert_to_tensor(img)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        step_size = tf.convert_to_tensor(step_size)\n",
    "        steps_remaining = steps\n",
    "        step = 0\n",
    "        while steps_remaining:\n",
    "            if steps_remaining>100:\n",
    "                run_steps = tf.constant(100)\n",
    "            else:\n",
    "                run_steps = tf.constant(steps_remaining)\n",
    "            steps_remaining -= run_steps\n",
    "            step += run_steps\n",
    "\n",
    "            loss, img = self(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_img = download(url, max_dim=500)\n",
    "base_model = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "\n",
    "# Maximize the activations of these layers\n",
    "names =  ['block5_conv1', 'block5_conv2']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "deepdream   = DeepDream(dream_model)\n",
    "Timer.start()\n",
    "dream_img   = deepdream.run_deep_dream_simple(img=original_img, steps=100, step_size=1.0)\n",
    "Timer.end()\n",
    "\n",
    "show_image(postprocess_image(dream_img))\n",
    "\n",
    "big = skimage.transform.pyramids.pyramid_expand(dream_img.numpy(), multichannel=True)\n",
    "big = tf.convert_to_tensor(big)\n",
    "show_image(postprocess_image(big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    out = tf.keras.applications.vgg19.preprocess_input(image)\n",
    "    out = tf.convert_to_tensor(out)\n",
    "    return out\n",
    "\n",
    "def postprocess_image(image):\n",
    "    image = image.numpy()\n",
    "    image[:, :, 0] += 103.939\n",
    "    image[:, :, 1] += 116.779\n",
    "    image[:, :, 2] += 123.68\n",
    "    out = np.clip(image[:, :, ::-1], 0, 255).astype('uint8')\n",
    "    return tf.convert_to_tensor(out)\n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "\n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "    name = url.split('/')[-1]\n",
    "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "    img = PIL.Image.open(image_path)\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "\n",
    "    return tf.math.reduce_mean(layer_activations)\n",
    "    \n",
    "    #     losses = []\n",
    "    #     for act in layer_activations:\n",
    "    #         loss = tf.math.reduce_mean(act)\n",
    "    #         losses.append(loss)\n",
    "\n",
    "    #     return  tf.reduce_sum(losses)\n",
    "\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # This needs gradients relative to `img`\n",
    "                # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            # img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img\n",
    "\n",
    "    def run_deep_dream_simple(self, img, steps=10, step_size=0.01):\n",
    "        # Convert from uint8 to the range expected by the model.\n",
    "        img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "        img = tf.convert_to_tensor(img)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        step_size = tf.convert_to_tensor(step_size)\n",
    "        steps_remaining = steps\n",
    "        step = 0\n",
    "        while steps_remaining:\n",
    "            if steps_remaining>100:\n",
    "                run_steps = tf.constant(100)\n",
    "            else:\n",
    "                run_steps = tf.constant(steps_remaining)\n",
    "            steps_remaining -= run_steps\n",
    "            step += run_steps\n",
    "\n",
    "            loss, img = self(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        return img\n",
    "\n",
    "base_model = tf.keras.applications.vgg19.VGG19(include_top=True, weights='imagenet')\n",
    "model      = Sequential(base_model.layers[:-1])\n",
    "\n",
    "# model.add(Flatten(data_format = 'channels_last', name = 'flatten'))\n",
    "\n",
    "# fc1 = Dense.from_config(base_model.layers[-3].get_config())\n",
    "# model.add(fc1)\n",
    "# fc1.set_weights(base_model.layers[-3].get_weights())\n",
    "\n",
    "# fc2 = Dense.from_config(base_model.layers[-2].get_config())\n",
    "# model.add(fc2)\n",
    "# fc2.set_weights(base_model.layers[-2].get_weights())\n",
    "\n",
    "top_config   = base_model.layers[-1].get_config()\n",
    "top_config['activation'] = 'relu'\n",
    "predictions = Dense.from_config(top_config)\n",
    "model.add(predictions)\n",
    "predictions.set_weights(base_model.layers[-1].get_weights())\n",
    "\n",
    "# Create the feature extraction model\n",
    "# names =  ['fc2', 'predictions']\n",
    "# names = ['predictions']\n",
    "# layers = [model.get_layer(name).output for name in names]\n",
    "# dream_model = tf.keras.Model(inputs=model.input, outputs=layers)\n",
    "# dream_model.build((None, 224, 224, 3))\n",
    "\n",
    "deepdream   = DeepDream(model)\n",
    "\n",
    "Timer.start()\n",
    "dream_img   = deepdream.run_deep_dream_simple(img=original_img, steps=100, step_size=0.5)\n",
    "Timer.end()\n",
    "\n",
    "show_image(postprocess_image(dream_img))\n",
    "\n",
    "big = skimage.transform.pyramids.pyramid_expand(dream_img.numpy(), multichannel=True)\n",
    "big = tf.convert_to_tensor(big)\n",
    "show_image(postprocess_image(big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.reddit.com/r/tensorflow/comments/e89v3q/inaccessibletensorerror_deepdream_tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    out = tf.keras.applications.vgg19.preprocess_input(image)\n",
    "    out = tf.convert_to_tensor(out)\n",
    "    return out\n",
    "\n",
    "def postprocess_image(image):\n",
    "    image = image.numpy()\n",
    "    image[:, :, 0] += 103.939\n",
    "    image[:, :, 1] += 116.779\n",
    "    image[:, :, 2] += 123.68\n",
    "    out = np.clip(image[:, :, ::-1], 0, 255).astype('uint8')\n",
    "    return tf.convert_to_tensor(out)\n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "\n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "    name = url.split('/')[-1]\n",
    "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "    img = PIL.Image.open(image_path)\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "\n",
    "    return tf.math.reduce_mean(layer_activations)\n",
    "    \n",
    "    #     losses = []\n",
    "    #     for act in layer_activations:\n",
    "    #         loss = tf.math.reduce_mean(act)\n",
    "    #         losses.append(loss)\n",
    "\n",
    "    #     return  tf.reduce_sum(losses)\n",
    "\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # This needs gradients relative to `img`\n",
    "                # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            # img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img\n",
    "\n",
    "    def run_deep_dream_simple(self, img, steps=10, step_size=0.01):\n",
    "        # Convert from uint8 to the range expected by the model.\n",
    "        img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "        img = tf.convert_to_tensor(img)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        step_size = tf.convert_to_tensor(step_size)\n",
    "        steps_remaining = steps\n",
    "        step = 0\n",
    "        while steps_remaining:\n",
    "            if steps_remaining>100:\n",
    "                run_steps = tf.constant(100)\n",
    "            else:\n",
    "                run_steps = tf.constant(steps_remaining)\n",
    "            steps_remaining -= run_steps\n",
    "            step += run_steps\n",
    "\n",
    "            loss, img = self(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        return img\n",
    "\n",
    "base_model = tf.keras.applications.vgg19.VGG19(include_top=True, weights='imagenet')\n",
    "model      = Sequential(base_model.layers[:-1])\n",
    "\n",
    "# model.add(Flatten(data_format = 'channels_last', name = 'flatten'))\n",
    "\n",
    "# fc1 = Dense.from_config(base_model.layers[-3].get_config())\n",
    "# model.add(fc1)\n",
    "# fc1.set_weights(base_model.layers[-3].get_weights())\n",
    "\n",
    "# fc2 = Dense.from_config(base_model.layers[-2].get_config())\n",
    "# model.add(fc2)\n",
    "# fc2.set_weights(base_model.layers[-2].get_weights())\n",
    "\n",
    "top_config   = base_model.layers[-1].get_config()\n",
    "top_config['activation'] = 'relu'\n",
    "predictions = Dense.from_config(top_config)\n",
    "model.add(predictions)\n",
    "predictions.set_weights(base_model.layers[-1].get_weights())\n",
    "\n",
    "# Create the feature extraction model\n",
    "# names =  ['fc2', 'predictions']\n",
    "# names = ['predictions']\n",
    "# layers = [model.get_layer(name).output for name in names]\n",
    "# dream_model = tf.keras.Model(inputs=model.input, outputs=layers)\n",
    "# dream_model.build((None, 224, 224, 3))\n",
    "\n",
    "deepdream   = DeepDream(model)\n",
    "\n",
    "Timer.start()\n",
    "dream_img   = deepdream.run_deep_dream_simple(img=original_img, steps=100, step_size=0.5)\n",
    "Timer.end()\n",
    "\n",
    "show_image(postprocess_image(dream_img))\n",
    "\n",
    "big = skimage.transform.pyramids.pyramid_expand(dream_img.numpy(), multichannel=True)\n",
    "big = tf.convert_to_tensor(big)\n",
    "show_image(postprocess_image(big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../dream-base-images/marco3.png'\n",
    "\n",
    "width = height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classnames\n",
    "df = pd.read_excel('../dataset/artist-breakdown-annotated.xlsx')\n",
    "df = df[df.fillna(0).keep.astype(bool)]\n",
    "class_names = df.artist.unique()\n",
    "class_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19-INet-down3'\n",
    "base_model = load_model(f'../classification/logs/models/{model_name}.hdf5')\n",
    "\n",
    "# Replace max pooling with avg pooling to promote gradient flow\n",
    "model = Sequential([InputLayer(input_shape = (width, height, 3))])\n",
    "\n",
    "for layer in base_model.layers[:-1]:\n",
    "    if isinstance(layer, MaxPooling2D):\n",
    "        pool = AvgPool2D().from_config(layer.get_config())\n",
    "        model.add(pool)\n",
    "    elif isinstance(layer, Dropout):\n",
    "        pass\n",
    "    else:\n",
    "        model.add(layer)\n",
    "        \n",
    "    if layer.name == 'block5_conv2':\n",
    "        break\n",
    "\n",
    "\n",
    "# # Add the top layer without softmax\n",
    "# top_config = base_model.layers[-1].get_config()\n",
    "# top_config['activation'] = 'linear'\n",
    "# top_layer = base_model.layers[-1].from_config(top_config)\n",
    "# model.add(top_layer)\n",
    "\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to manage the image processing pre- and post-dream.\n",
    "# Terminology\n",
    "#  - The base image is what is dreamt upon by the dreamer.\n",
    "#     The base image itself can be an earlier dream\n",
    "#  - After dreaming, a dream should be registered with the DreamImage instance\n",
    "#  - Then it can be decoded using a normalization scheme and optional resizing\n",
    "\n",
    "# Scalers\n",
    "def min_max_scale(tensor):\n",
    "    min_ = tf.reduce_min(tensor)\n",
    "    max_ = tf.reduce_max(tensor)\n",
    "    return (tensor - min_) / (max_ - min_)\n",
    "def clip_scaler(tensor):\n",
    "    return (1/2) * (1 + tf.clip_by_value(tensor, -1, 1))\n",
    "\n",
    "\n",
    "class DreamImage:\n",
    "    def __init__(self, image_path, width, height, normalizer = 'min-max'):\n",
    "        # Load the image from disk\n",
    "        self.img = tf.io.read_file(image_path)\n",
    "        if image_path.endswith('.png'):\n",
    "            self.img = tf.image.decode_png(self.img, channels = 3)\n",
    "        elif image_path.endswith('.jpg'):\n",
    "            self.img = tf.image.decode_jpg(self.img, channels = 3)\n",
    "        else:\n",
    "            raise TypeError(f'File format for {path} not supported or detected')\n",
    "        self.img = tf.image.convert_image_dtype(self.img, tf.float32)\n",
    "        \n",
    "        # Set the target width and height\n",
    "        self.width  = width\n",
    "        self.height = height\n",
    "        \n",
    "        # Set the normalizer\n",
    "        normalizers = {\n",
    "            'sigmoid' : tf.sigmoid,\n",
    "            'min-max' : min_max_scale,\n",
    "            'clip'    : clip_scaler\n",
    "        }\n",
    "        self.normalizer = normalizers[normalizer]\n",
    "        \n",
    "    def show_base(self):\n",
    "        show_image(self.img)\n",
    "        \n",
    "    def prepare_base(self):\n",
    "        # Resize\n",
    "        self.resized_base = tf.image.resize(self.img, [self.width, self.height])\n",
    "        \n",
    "        # Center the image\n",
    "        # self.mean_correction = tf.reduce_mean(self.resized_base)\n",
    "        self.mean_correction = 0\n",
    "        \n",
    "        # img = self.resized_base - self.mean_correction\n",
    "        img = self.resized_base\n",
    "        \n",
    "        # Add noise\n",
    "        img = img + tf.random.normal(img.shape, stddev = .05)\n",
    "        \n",
    "        img = tf.expand_dims(img, axis = 0)\n",
    "        return img\n",
    "        \n",
    "    def decode_dream(self, dream, full_size = False):\n",
    "        # Prepare the dream\n",
    "        dream    = tf.squeeze(dream)\n",
    "        dream    = self.normalizer(dream)\n",
    "        \n",
    "        if full_size:\n",
    "            dream_delta = dream - self.resized_base\n",
    "            dream_delta = tf.image.resize(dream_delta, self.img.shape.as_list()[:-1])\n",
    "            img         = dream_delta + self.img\n",
    "        else:\n",
    "            img         = dream\n",
    "        img         = img - tf.reduce_min(img)\n",
    "        img         = img / tf.reduce_max(img)\n",
    "        return img\n",
    "\n",
    "    def show_dream(self, dream, full_size = False):\n",
    "        dream = self.decode_dream(dream, full_size = full_size)\n",
    "        show_image(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model, steps, learning_rate, artist_vect):\n",
    "        self.model         = model\n",
    "        self.steps         = tf.convert_to_tensor(steps, dtype = tf.int32)\n",
    "        self.learning_rate = tf.convert_to_tensor(learning_rate, dtype = tf.float32)\n",
    "        self.artist_vect   = tf.convert_to_tensor(artist_vect, dtype = tf.float32)\n",
    "        \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[1,None,None,3], dtype=tf.float32),))\n",
    "    def __call__(self, img):\n",
    "        for n in tf.range(self.steps):\n",
    "            # Compute the loss so that the gradient may be computed\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(img)\n",
    "                activations = self.model(img)\n",
    "                loss = tf.reduce_sum(tf.math.square(activations))\n",
    "                # loss        = tf.tensordot(self.artist_vect, activations, [0,1])\n",
    "                # loss        = tf.squeeze(loss)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            # gradients -= tf.math.reduce_mean(gradients)\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*self.learning_rate\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamer = DeepDream(model, 100, 0.01, class_names == 'Pablo Picasso')\n",
    "marco   = DreamImage(image_path, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timer.start()\n",
    "dream = dreamer(marco.prepare_base())\n",
    "Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marco.show_dream(dream, full_size = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
